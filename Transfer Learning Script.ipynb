{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from IPython.core.debugger import Tracer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'Data/train'\n",
    "validation_data_dir = 'Data/val'\n",
    "nb_train_samples = 1800\n",
    "nb_validation_samples = 200\n",
    "epochs = 10 #50\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class auc_roc_callback(keras.callbacks.Callback):\n",
    "    def __init__(self, val_data_generator, val_labels, weight_file_path):\n",
    "        self.val_data_generator = val_data_generator\n",
    "        self.val_labels = val_labels\n",
    "        self.val_samples = val_labels.shape[0]\n",
    "        self.weight_file_path = weight_file_path\n",
    "        self.best_AUC_Score = float(\"-inf\")\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.auc_history = []\n",
    "        self.loss = []\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict_generator(self.val_data_generator, self.val_samples)\n",
    "        self.auc_history.append(roc_auc_score(self.val_labels, y_pred))\n",
    "        print '\\n AUC Score: ', self.auc_history[-1]\n",
    "        \n",
    "        #Saving the model weights if the AUC score is the best observed till now\n",
    "        if self.best_AUC_Score < self.auc_history[-1]:\n",
    "            dateTag = str(datetime.now().replace(second=0, microsecond=0)).replace(' ', '_').replace('-', '_').replace(':', '_')\n",
    "            filepath = self.weight_file_path.format(str(round(self.auc_history[-1] * 100, 5)).replace('.', '_'), dateTag)\n",
    "            print('Epoch %05d: AUC improved from %0.5f to %0.5f,'\n",
    "                    ' saving model to %s'\n",
    "                    % (epoch + 1, self.best_AUC_Score, self.auc_history[-1],\n",
    "                       filepath))\n",
    "            self.best_AUC_Score = self.auc_history[-1]\n",
    "            self.model.save_weights(filepath, overwrite=True)\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Model loaded.', (512, 4, 4))\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(3, img_width, img_height),name = 'image_input')\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input)\n",
    "print('Model loaded.', model.output_shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 512, 4, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.random.random_sample((24, 3,150,150))\n",
    "train_y = (np.random.random_sample(24) > 0.8).astype(int)\n",
    "\n",
    "val_x = np.random.random_sample((24, 3,150,150))\n",
    "val_y = (np.random.random_sample(24) > 0.8).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "50/72 [===================>..........] - ETA: 6s - loss: 0.3262 - acc: 0.8800 \n",
      " AUC Score:  0.599165305752\n",
      "Epoch 00001: AUC improved from -inf to 0.59917, saving model to trainedmodel/weights_fineTuning_layersFreezed_AUC_59_91653_time_2017_10_29_18_49_00.hdf5\n",
      "75/72 [===============================] - 302s - loss: 0.7711 - acc: 0.8667 - val_loss: 0.7683 - val_acc: 0.5800\n",
      "Epoch 2/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 1.1147 - acc: 0.7000\n",
      " AUC Score:  0.417347123934\n",
      "75/72 [===============================] - 280s - loss: 1.2958 - acc: 0.6533 - val_loss: 1.2839 - val_acc: 0.2250\n",
      "Epoch 3/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 1.2673 - acc: 0.3000\n",
      " AUC Score:  0.546361821811\n",
      "75/72 [===============================] - 287s - loss: 1.2266 - acc: 0.3200 - val_loss: 1.4507 - val_acc: 0.1850\n",
      "Epoch 4/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 1.1792 - acc: 0.4000\n",
      " AUC Score:  0.399836690256\n",
      "75/72 [===============================] - 282s - loss: 1.1745 - acc: 0.3467 - val_loss: 1.3260 - val_acc: 0.1950\n",
      "Epoch 5/10\n",
      "50/72 [===================>..........] - ETA: 3s - loss: 1.2155 - acc: 0.3400\n",
      " AUC Score:  0.572854291417\n",
      "75/72 [===============================] - 282s - loss: 1.2186 - acc: 0.2933 - val_loss: 1.0785 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "50/72 [===================>..........] - ETA: 3s - loss: 1.0000 - acc: 0.3200\n",
      " AUC Score:  0.43240791145\n",
      "75/72 [===============================] - 282s - loss: 0.9902 - acc: 0.3200 - val_loss: 0.9051 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      "50/72 [===================>..........] - ETA: 3s - loss: 0.9973 - acc: 0.3600\n",
      " AUC Score:  0.40827436037\n",
      "75/72 [===============================] - 282s - loss: 1.1090 - acc: 0.3600 - val_loss: 0.8380 - val_acc: 0.2900\n",
      "Epoch 8/10\n",
      "50/72 [===================>..........] - ETA: 3s - loss: 1.3954 - acc: 0.5800\n",
      " AUC Score:  0.56323716204\n",
      "75/72 [===============================] - 282s - loss: 1.2272 - acc: 0.4933 - val_loss: 0.8493 - val_acc: 0.2900\n",
      "Epoch 9/10\n",
      "50/72 [===================>..........] - ETA: 3s - loss: 1.1756 - acc: 0.3800\n",
      " AUC Score:  0.630103429505\n",
      "Epoch 00009: AUC improved from 0.59917 to 0.63010, saving model to trainedmodel/weights_fineTuning_layersFreezed_AUC_63_01034_time_2017_10_29_19_27_00.hdf5\n",
      "75/72 [===============================] - 280s - loss: 1.1367 - acc: 0.4267 - val_loss: 0.8243 - val_acc: 0.3400\n",
      "Epoch 10/10\n",
      "50/72 [===================>..........] - ETA: 3s - loss: 1.2716 - acc: 0.5800\n",
      " AUC Score:  0.39539103611\n",
      "75/72 [===============================] - 279s - loss: 1.0922 - acc: 0.5867 - val_loss: 0.8344 - val_acc: 0.3800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nmdl.fit(\\n    train_x,\\n    train_y,\\n    #samples_per_epoch=nb_train_samples,\\n    batch_size = batch_size,\\n    nb_epoch=epochs,\\n    validation_data=(val_x, val_y),\\n    #nb_val_samples=nb_validation_samples,\\n    callbacks=[auc_roc_hist, checkpointer])\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the model on top of the convolutional base\n",
    "#Freezing the top 15 layers i.e. just before the last conv layer\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "mdl = Model(input= model.input, output= top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "mdl.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, nesterov = True, decay = 0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255)\n",
    "'''\n",
    "    rotation_range=95,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2)\n",
    "'''\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "#Creating the callbacks\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "val_labels = np.array([0]*167 + [1]*33)\n",
    "#checkpointer = ModelCheckpoint(filepath=\"trainedmodel/weights_fineTuning_layersFreezed_AUC_{}_time_{}.hdf5\", verbose=1, save_best_only=True)\n",
    "auc_roc_hist = auc_roc_callback(val_generator, val_labels, \"trainedmodel/weights_fineTuning_layersFreezed_AUC_{}_time_{}.hdf5\")\n",
    "\n",
    "# fine-tune the model\n",
    "class_weight = {0 : 1.,\n",
    "    1: 6.}\n",
    "mdl.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples // batch_size,\n",
    "    nb_epoch=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples,\n",
    "    callbacks=[auc_roc_hist],\n",
    "    class_weight = class_weight)\n",
    "'''\n",
    "\n",
    "mdl.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    #samples_per_epoch=nb_train_samples,\n",
    "    batch_size = batch_size,\n",
    "    nb_epoch=epochs,\n",
    "    validation_data=(val_x, val_y),\n",
    "    #nb_val_samples=nb_validation_samples,\n",
    "    callbacks=[auc_roc_hist, checkpointer])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with adaptive learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Model loaded.', (512, 4, 4))\n",
      "Found 1800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /Users/shashankbhushan/.theano/compiledir_Darwin-16.7.0-x86_64-i386-64bit-i386-2.7.14-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/72 [===================>..........] - ETA: 6s - loss: 1.3909 - acc: 0.8800 \n",
      " AUC Score:  0.5\n",
      "Epoch 00001: AUC improved from -inf to 0.50000, saving model to trainedmodel/weights_fineTuning_AdamOpt_layersFreezed_AUC_50_0_time_2017_10_29_16_52_00.hdf5\n",
      "75/72 [===============================] - 288s - loss: 1.1421 - acc: 0.9067 - val_loss: 2.6595 - val_acc: 0.8350\n",
      "Epoch 2/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 4.1907 - acc: 0.7400\n",
      " AUC Score:  0.5\n",
      "75/72 [===============================] - 279s - loss: 3.2236 - acc: 0.8000 - val_loss: 2.6595 - val_acc: 0.8350\n",
      "Epoch 3/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 2.9013 - acc: 0.8200\n",
      " AUC Score:  0.5\n",
      "75/72 [===============================] - 277s - loss: 2.5789 - acc: 0.8400 - val_loss: 2.6595 - val_acc: 0.8350\n",
      "Epoch 4/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 3.2236 - acc: 0.8000\n",
      " AUC Score:  0.5\n",
      "75/72 [===============================] - 279s - loss: 3.2236 - acc: 0.8000 - val_loss: 2.6595 - val_acc: 0.8350\n",
      "Epoch 5/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 2.9013 - acc: 0.8200\n",
      " AUC Score:  0.5\n",
      "75/72 [===============================] - 283s - loss: 3.2236 - acc: 0.8000 - val_loss: 2.6595 - val_acc: 0.8350\n",
      "Epoch 6/10\n",
      "50/72 [===================>..........] - ETA: 4s - loss: 3.2236 - acc: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1f030f918f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_validation_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     callbacks=[auc_roc_hist_adap])\n\u001b[0m",
      "\u001b[0;32m/Users/shashankbhushan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                         val_outs = self.evaluate_generator(validation_data,\n\u001b[1;32m   1470\u001b[0m                                                            \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                                                            max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                         \u001b[0;31m# no need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shashankbhushan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1534\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input = Input(shape=(3, img_width, img_height),name = 'image_input')\n",
    "model_adaptive = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input)\n",
    "print('Model loaded.', model_adaptive.output_shape[1:])\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#Freezing the top 15 layers i.e. just before the last conv layer\n",
    "for layer in model_adaptive.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "mdl_adap = Model(input= model_adaptive.input, output= top_model(model_adaptive.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "mdl_adap.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "#Creating the callbacks\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "val_labels = np.array([0]*167 + [1]*33)\n",
    "#checkpointer = ModelCheckpoint(filepath=\"trainedmodel/weights_fineTuning_layersFreezed_AUC_{}_time_{}.hdf5\", verbose=1, save_best_only=True)\n",
    "auc_roc_hist_adap = auc_roc_callback(val_generator, val_labels, \"trainedmodel/weights_fineTuning_AdamOpt_layersFreezed_AUC_{}_time_{}.hdf5\")\n",
    "\n",
    "# fine-tune the model\n",
    "\n",
    "mdl_adap.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples // batch_size,\n",
    "    nb_epoch=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples,\n",
    "    callbacks=[auc_roc_hist_adap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6875,\n",
       " 0.59999999999999998,\n",
       " 0.70000000000000007,\n",
       " 0.59999999999999998,\n",
       " 0.71250000000000002,\n",
       " 0.59999999999999998,\n",
       " 0.71250000000000002,\n",
       " 0.59999999999999998,\n",
       " 0.71250000000000002,\n",
       " 0.59999999999999998]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_roc_hist.auc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (None, 3, 150, 150)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 64, 150, 150)  1792        image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 64, 150, 150)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, 75, 75)    0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 128, 75, 75)   73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 128, 75, 75)   147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 128, 37, 37)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 256, 37, 37)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 256, 37, 37)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 256, 37, 37)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 256, 18, 18)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 512, 18, 18)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 512, 18, 18)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 512, 18, 18)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 512, 9, 9)     0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 512, 9, 9)     2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 512, 9, 9)     2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 512, 9, 9)     2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 512, 4, 4)     0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14714688\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.topology.InputLayer object at 0x1c279e0250>\n",
      "1 <keras.layers.convolutional.Convolution2D object at 0x1c279e0110>\n",
      "2 <keras.layers.convolutional.Convolution2D object at 0x1c1effd390>\n",
      "3 <keras.layers.pooling.MaxPooling2D object at 0x1138228d0>\n",
      "4 <keras.layers.convolutional.Convolution2D object at 0x113822a90>\n",
      "5 <keras.layers.convolutional.Convolution2D object at 0x11377d650>\n",
      "6 <keras.layers.pooling.MaxPooling2D object at 0x113783f90>\n",
      "7 <keras.layers.convolutional.Convolution2D object at 0x113783b90>\n",
      "8 <keras.layers.convolutional.Convolution2D object at 0x11384d450>\n",
      "9 <keras.layers.convolutional.Convolution2D object at 0x113853bd0>\n",
      "10 <keras.layers.pooling.MaxPooling2D object at 0x1c1ce13710>\n",
      "11 <keras.layers.convolutional.Convolution2D object at 0x1c1ce138d0>\n",
      "12 <keras.layers.convolutional.Convolution2D object at 0x1c1ce36490>\n",
      "13 <keras.layers.convolutional.Convolution2D object at 0x1c1ce4aed0>\n",
      "14 <keras.layers.pooling.MaxPooling2D object at 0x1c1ce67a90>\n",
      "15 <keras.layers.convolutional.Convolution2D object at 0x1c1ce67c50>\n",
      "16 <keras.layers.convolutional.Convolution2D object at 0x1c1ce89810>\n",
      "17 <keras.layers.convolutional.Convolution2D object at 0x1c1ce963d0>\n",
      "18 <keras.layers.pooling.MaxPooling2D object at 0x1c1cec6f50>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers[:25]):\n",
    "    print i, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.topology.InputLayer object at 0x1c279e0250>\n",
      "1 <keras.layers.convolutional.Convolution2D object at 0x1c279e0110>\n",
      "2 <keras.layers.convolutional.Convolution2D object at 0x1c1effd390>\n",
      "3 <keras.layers.pooling.MaxPooling2D object at 0x1138228d0>\n",
      "4 <keras.layers.convolutional.Convolution2D object at 0x113822a90>\n",
      "5 <keras.layers.convolutional.Convolution2D object at 0x11377d650>\n",
      "6 <keras.layers.pooling.MaxPooling2D object at 0x113783f90>\n",
      "7 <keras.layers.convolutional.Convolution2D object at 0x113783b90>\n",
      "8 <keras.layers.convolutional.Convolution2D object at 0x11384d450>\n",
      "9 <keras.layers.convolutional.Convolution2D object at 0x113853bd0>\n",
      "10 <keras.layers.pooling.MaxPooling2D object at 0x1c1ce13710>\n",
      "11 <keras.layers.convolutional.Convolution2D object at 0x1c1ce138d0>\n",
      "12 <keras.layers.convolutional.Convolution2D object at 0x1c1ce36490>\n",
      "13 <keras.layers.convolutional.Convolution2D object at 0x1c1ce4aed0>\n",
      "14 <keras.layers.pooling.MaxPooling2D object at 0x1c1ce67a90>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers[:15]):\n",
    "    print i, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (None, 3, 150, 150)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 64, 150, 150)  0           image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 64, 150, 150)  0           block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, 75, 75)    0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 128, 75, 75)   0           block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 128, 75, 75)   0           block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 128, 37, 37)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 256, 37, 37)   0           block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 256, 37, 37)   0           block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 256, 37, 37)   0           block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 256, 18, 18)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 512, 18, 18)   0           block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 512, 18, 18)   0           block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 512, 18, 18)   0           block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 512, 9, 9)     0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 512, 9, 9)     2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 512, 9, 9)     2359808     block5_conv1[0][0]               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /Users/shashankbhushan/.theano/compiledir_Darwin-16.7.0-x86_64-i386-64bit-i386-2.7.14-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 512, 9, 9)     2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 512, 4, 4)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)        (None, 1)             2097665     block5_pool[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 9177089\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
